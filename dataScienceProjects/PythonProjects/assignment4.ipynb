{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Assignment 4 - FARS Analysis\n",
    "   ## Written by: Kazeem Tijani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each state, what day of the week has the most accidents? Use the __DAY_WEEK__ column. Output the day and the      count. For the values output the day name, where 1 is Sunday, 2 is Monday, ... and 7 is Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateName = {1:'Alabama',2:'Alaska',4:'Arizona',5:'Arkansas',6:'California',8:'Colorado',9:'Connecticut',\n",
    "                               10:'Delaware',11:'District of Columbia',12:'Florida',13:'Georgia',15:'Hawaii',16:'Idaho',\n",
    "                               17:'Illinois',18:'Indiana',19:'Iowa',20:'Kansas',\n",
    "                               21:'Kentucky',22:'Louisiana',23:'Maine',24:'Maryland',25:'Massachusetts',26:'Michigan',\n",
    "                               27:'Minnesota',28:'Mississippi',29:'Missouri',30:'Montana',31:'Nebraska',32:'Nevada',\n",
    "                               33:'New Hampshire',34:'New Jersey',35:'New Mexico',\n",
    "                           36:'New York',37:'North Carolina',38:'North Dakota',39:'Ohio',40:'Oklahoma',41:'Oregon',42:'Pennsylvania',\n",
    "                               43:'Puerto Rico',44:'Rhode Island',45:'South Carolina',46:'South Dakota',47:'Tennessee',\n",
    "                               48:'Texas',49:'Utah',\n",
    "                               50:'Vermont',52:'Virgin Islands (since 2004)',51:'Virginia',53:'Washington',\n",
    "                               54:'West Virginia',55:'Wisconsin',56:'Wyoming'}\n",
    "day_to_weekDay = {1:'Sunday',2:'Monday',3:'Tuesday',4:'Wednesday',5:'Thursday',6:'Friday',7:'Saturday'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ['Alabama'],the day of the week with the most accidents is: Saturday with count: 166\n",
      "For ['Alaska'],the day of the week with the most accidents is: Friday with count: 15\n",
      "For ['Arizona'],the day of the week with the most accidents is: Saturday with count: 150\n",
      "For ['Arkansas'],the day of the week with the most accidents is: Monday with count: 85\n",
      "For ['California'],the day of the week with the most accidents is: Saturday with count: 614\n",
      "For ['Colorado'],the day of the week with the most accidents is: Friday with count: 95\n",
      "For ['Connecticut'],the day of the week with the most accidents is: Thursday with count: 50\n",
      "For ['Delaware'],the day of the week with the most accidents is: Saturday with count: 26\n",
      "For ['District of Columbia'],the day of the week with the most accidents is: Friday with count: 5\n",
      "For ['Florida'],the day of the week with the most accidents is: Saturday with count: 507\n",
      "For ['Georgia'],the day of the week with the most accidents is: Saturday with count: 258\n",
      "For ['Hawaii'],the day of the week with the most accidents is: Saturday with count: 25\n",
      "For ['Idaho'],the day of the week with the most accidents is: Friday with count: 38\n",
      "For ['Illinois'],the day of the week with the most accidents is: Saturday with count: 202\n",
      "For ['Indiana'],the day of the week with the most accidents is: Friday with count: 127\n",
      "For ['Iowa'],the day of the week with the most accidents is: Saturday with count: 65\n",
      "For ['Kansas'],the day of the week with the most accidents is: Saturday with count: 63\n",
      "For ['Kentucky'],the day of the week with the most accidents is: Saturday with count: 133\n",
      "For ['Louisiana'],the day of the week with the most accidents is: Sunday with count: 128\n",
      "For ['Maine'],the day of the week with the most accidents is: Saturday with count: 30\n",
      "For ['Maryland'],the day of the week with the most accidents is: Saturday with count: 96\n",
      "For ['Massachusetts'],the day of the week with the most accidents is: Saturday with count: 61\n",
      "For ['Michigan'],the day of the week with the most accidents is: Saturday with count: 175\n",
      "For ['Minnesota'],the day of the week with the most accidents is: Saturday with count: 58\n",
      "For ['Mississippi'],the day of the week with the most accidents is: Saturday with count: 118\n",
      "For ['Missouri'],the day of the week with the most accidents is: Saturday with count: 156\n",
      "For ['Montana'],the day of the week with the most accidents is: Saturday with count: 34\n",
      "For ['Nebraska'],the day of the week with the most accidents is: Sunday with count: 38\n",
      "For ['Nevada'],the day of the week with the most accidents is: Saturday with count: 56\n",
      "For ['New Hampshire'],the day of the week with the most accidents is: Friday with count: 26\n",
      "For ['New Jersey'],the day of the week with the most accidents is: Saturday with count: 105\n",
      "For ['New Mexico'],the day of the week with the most accidents is: Saturday with count: 69\n",
      "For ['New York'],the day of the week with the most accidents is: Saturday with count: 159\n",
      "For ['North Carolina'],the day of the week with the most accidents is: Saturday with count: 219\n",
      "For ['North Dakota'],the day of the week with the most accidents is: Saturday with count: 22\n",
      "For ['Ohio'],the day of the week with the most accidents is: Saturday with count: 194\n",
      "For ['Oklahoma'],the day of the week with the most accidents is: Saturday with count: 109\n",
      "For ['Oregon'],the day of the week with the most accidents is: Saturday with count: 76\n",
      "For ['Pennsylvania'],the day of the week with the most accidents is: Friday with count: 186\n",
      "For ['Rhode Island'],the day of the week with the most accidents is: Thursday with count: 14\n",
      "For ['South Carolina'],the day of the week with the most accidents is: Saturday with count: 182\n",
      "For ['South Dakota'],the day of the week with the most accidents is: Saturday with count: 18\n",
      "For ['Tennessee'],the day of the week with the most accidents is: Saturday with count: 187\n",
      "For ['Texas'],the day of the week with the most accidents is: Saturday with count: 604\n",
      "For ['Utah'],the day of the week with the most accidents is: Saturday with count: 44\n",
      "For ['Vermont'],the day of the week with the most accidents is: Wednesday with count: 11\n",
      "For ['Virginia'],the day of the week with the most accidents is: Saturday with count: 139\n",
      "For ['Washington'],the day of the week with the most accidents is: Saturday with count: 87\n",
      "For ['West Virginia'],the day of the week with the most accidents is: Wednesday with count: 41\n",
      "For ['Wisconsin'],the day of the week with the most accidents is: Saturday with count: 112\n",
      "For ['Wyoming'],the day of the week with the most accidents is: Thursday with count: 19\n"
     ]
    }
   ],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "US_DF = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['STATE'] = df['STATE'].map(lambda x:stateName[x])\n",
    "    df['DAY_WEEK'] = df['DAY_WEEK'].map(lambda x:day_to_weekDay[x])\n",
    "    US_DF.append(df)\n",
    "    for st in US_DF:\n",
    "        unique, counts = np.unique(st['DAY_WEEK'], return_counts=True)\n",
    "        my_list = list(zip(unique, counts))\n",
    "        index, value = max(my_list, key=lambda item: item[1])\n",
    "    print('For {},the day of the week with the most accidents is: {} with count: {}'.format(pd.unique(st['STATE']),index,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then made a list to store all the data for each state. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName as well as the Day_week.\n",
    "\n",
    "* For each state in the US_df list, I want to return the unique state and the count of each day of the week and then get the day of the week with the maximum value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For whole United States, i.e., all the data, what day of the week has the most accidents? Output the day and the count.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the whole United States, the day of the week with the most accident is Saturday with 6104 counts\n"
     ]
    }
   ],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "for file in files:\n",
    "    US_df = pd.concat([pd.read_csv(file) for file in files], ignore_index = True)\n",
    "    US_df['STATE'] = US_df['STATE'].map(lambda x:stateName[x])\n",
    "    day_to_weekDay = {1:'Sunday',2:'Monday',3:'Tuesday',4:'Wednesday',5:'Thursday',6:'Friday',7:'Saturday'}\n",
    "    US_df['DAY_WEEK'] = US_df['DAY_WEEK'].map(lambda x:day_to_weekDay[x])\n",
    "data = pd.DataFrame(US_df)\n",
    "unique, counts = np.unique(data['DAY_WEEK'], return_counts=True)\n",
    "my_list = list(zip(unique, counts))\n",
    "index, value = max(my_list, key=lambda item: item[1])\n",
    "print('For the whole United States, the day of the week with the most accident is {} with {} counts'.format(index,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then concatenated all the data for each state to represent the data for the whole United States. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName as well as the Day_week.\n",
    "\n",
    "* I made a pandas dataFrame for the whole US_df which is the concatenated data of all the states, I want to return the unique day of the week with the count and then get the day of the week with the maximum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each state, what hour of the day has the most accidents? Output the hour and the count.\n",
    "    - A value of 99 in the HOUR means unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ['Alabama'],the hour with most accident is: 16 with count = 54\n",
      "For ['Alaska'],the hour with most accident is: 5 with count = 7\n",
      "For ['Arizona'],the hour with most accident is: 19 with count = 65\n",
      "For ['Arkansas'],the hour with most accident is: 17 with count = 39\n",
      "For ['California'],the hour with most accident is: 20 with count = 210\n",
      "For ['Colorado'],the hour with most accident is: 13 with count = 38\n",
      "For ['Connecticut'],the hour with most accident is: 17 with count = 22\n",
      "For ['Delaware'],the hour with most accident is: 21 with count = 10\n",
      "For ['District of Columbia'],the hour with most accident is: 2 with count = 4\n",
      "For ['Florida'],the hour with most accident is: 21 with count = 208\n",
      "For ['Georgia'],the hour with most accident is: 18 with count = 84\n",
      "For ['Hawaii'],the hour with most accident is: 20 with count = 10\n",
      "For ['Idaho'],the hour with most accident is: 16 with count = 17\n",
      "For ['Illinois'],the hour with most accident is: 16 with count = 64\n",
      "For ['Indiana'],the hour with most accident is: 17 with count = 50\n",
      "For ['Iowa'],the hour with most accident is: 17 with count = 26\n",
      "For ['Kansas'],the hour with most accident is: 16 with count = 28\n",
      "For ['Kentucky'],the hour with most accident is: 16 with count = 57\n",
      "For ['Louisiana'],the hour with most accident is: 17 with count = 48\n",
      "For ['Maine'],the hour with most accident is: 18 with count = 12\n",
      "For ['Maryland'],the hour with most accident is: 22 with count = 32\n",
      "For ['Massachusetts'],the hour with most accident is: 22 with count = 25\n",
      "For ['Michigan'],the hour with most accident is: 15 with count = 59\n",
      "For ['Minnesota'],the hour with most accident is: 15 with count = 28\n",
      "For ['Mississippi'],the hour with most accident is: 17 with count = 41\n",
      "For ['Missouri'],the hour with most accident is: 18 with count = 57\n",
      "For ['Montana'],the hour with most accident is: 15 with count = 13\n",
      "For ['Nebraska'],the hour with most accident is: 99 with count = 29\n",
      "For ['Nevada'],the hour with most accident is: 23 with count = 22\n",
      "For ['New Hampshire'],the hour with most accident is: 16 with count = 11\n",
      "For ['New Jersey'],the hour with most accident is: 18 with count = 42\n",
      "For ['New Mexico'],the hour with most accident is: 20 with count = 31\n",
      "For ['New York'],the hour with most accident is: 17 with count = 59\n",
      "For ['North Carolina'],the hour with most accident is: 18 with count = 92\n",
      "For ['North Dakota'],the hour with most accident is: 16 with count = 9\n",
      "For ['Ohio'],the hour with most accident is: 19 with count = 77\n",
      "For ['Oklahoma'],the hour with most accident is: 16 with count = 41\n",
      "For ['Oregon'],the hour with most accident is: 17 with count = 31\n",
      "For ['Pennsylvania'],the hour with most accident is: 17 with count = 64\n",
      "For ['Rhode Island'],the hour with most accident is: 1 with count = 6\n",
      "For ['South Carolina'],the hour with most accident is: 17 with count = 64\n",
      "For ['South Dakota'],the hour with most accident is: 14 with count = 10\n",
      "For ['Tennessee'],the hour with most accident is: 16 with count = 61\n",
      "For ['Texas'],the hour with most accident is: 20 with count = 200\n",
      "For ['Utah'],the hour with most accident is: 13 with count = 26\n",
      "For ['Vermont'],the hour with most accident is: 15 with count = 6\n",
      "For ['Virginia'],the hour with most accident is: 17 with count = 60\n",
      "For ['Washington'],the hour with most accident is: 15 with count = 34\n",
      "For ['West Virginia'],the hour with most accident is: 15 with count = 24\n",
      "For ['Wisconsin'],the hour with most accident is: 17 with count = 45\n",
      "For ['Wyoming'],the hour with most accident is: 12 with count = 11\n"
     ]
    }
   ],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "US_DF = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['STATE'] = df['STATE'].map(lambda x:stateName[x])\n",
    "    US_DF.append(df)\n",
    "    for st in US_DF:\n",
    "        unique, counts = np.unique(st['HOUR'], return_counts=True)\n",
    "        my_list = list(zip(unique, counts))\n",
    "        index, value = max(my_list, key=lambda item: item[1])\n",
    "    print('For {},the hour with most accident is: {} with count = {}'.format(pd.unique(st['STATE']),index,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then made a list to store all the data for each state. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName as well as the Day_week.\n",
    "\n",
    "* For each state in the US_df list, I want to return the unique state and the count of the hour with the most accident. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For whole United States, what hour of the day has the most accidents? Output the hour and the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the whole United States, the hour with the most accident is 18 with counts: 1984\n"
     ]
    }
   ],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "US_df = pd.concat([pd.read_csv(file) for file in files], ignore_index = True)\n",
    "US_df['STATE'] = US_df['STATE'].map(lambda x:stateName[x])\n",
    "for file in files:\n",
    "    data = pd.DataFrame(US_df)\n",
    "    unique, counts = np.unique(data['HOUR'], return_counts=True)\n",
    "    my_list = list(zip(unique, counts))\n",
    "    #print(my_list)\n",
    "    index, value = max(my_list, key=lambda item: item[1])\n",
    "print('For the whole United States, the hour with the most accident is {} with counts: {}'.format(index,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then concatenated all the data for each state to represent the data for the whole United States. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName as well as the Day_week.\n",
    "\n",
    "* I made a pandas dataFrame for the whole US_df which is the concatenated data of all the states, I want to return the hour of the day with the most accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. For each state, what is the percentage of fatal accidents involved at least one drunk driver? If the column, DRUNK_DR, has a 0, then no drunk drivers were involved. Any number larger than 0 indicates the number of drunk drivers involved in the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Alabama the percentage of fatal accidents involving at least one drunk driver = 14.621131270010673\n",
      "For Alaska the percentage of fatal accidents involving at least one drunk driver = 44.871794871794876\n",
      "For Arizona the percentage of fatal accidents involving at least one drunk driver = 23.352601156069362\n",
      "For Arkansas the percentage of fatal accidents involving at least one drunk driver = 23.36065573770492\n",
      "For California the percentage of fatal accidents involving at least one drunk driver = 23.443550789395292\n",
      "For Colorado the percentage of fatal accidents involving at least one drunk driver = 33.691756272401435\n",
      "For Connecticut the percentage of fatal accidents involving at least one drunk driver = 29.537366548042705\n",
      "For Delaware the percentage of fatal accidents involving at least one drunk driver = 31.03448275862069\n",
      "For District of Columbia the percentage of fatal accidents involving at least one drunk driver = 38.46153846153847\n",
      "For Florida the percentage of fatal accidents involving at least one drunk driver = 21.241050119331742\n",
      "For Georgia the percentage of fatal accidents involving at least one drunk driver = 21.729957805907173\n",
      "For Hawaii the percentage of fatal accidents involving at least one drunk driver = 24.770642201834864\n",
      "For Idaho the percentage of fatal accidents involving at least one drunk driver = 28.448275862068968\n",
      "For Illinois the percentage of fatal accidents involving at least one drunk driver = 26.420737786640082\n",
      "For Indiana the percentage of fatal accidents involving at least one drunk driver = 17.708333333333336\n",
      "For Iowa the percentage of fatal accidents involving at least one drunk driver = 25.842696629213485\n",
      "For Kansas the percentage of fatal accidents involving at least one drunk driver = 20.47244094488189\n",
      "For Kentucky the percentage of fatal accidents involving at least one drunk driver = 24.901703800786372\n",
      "For Louisiana the percentage of fatal accidents involving at least one drunk driver = 29.545454545454547\n",
      "For Maine the percentage of fatal accidents involving at least one drunk driver = 31.125827814569533\n",
      "For Maryland the percentage of fatal accidents involving at least one drunk driver = 23.728813559322035\n",
      "For Massachusetts the percentage of fatal accidents involving at least one drunk driver = 28.690807799442897\n",
      "For Michigan the percentage of fatal accidents involving at least one drunk driver = 24.79591836734694\n",
      "For Minnesota the percentage of fatal accidents involving at least one drunk driver = 27.73109243697479\n",
      "For Mississippi the percentage of fatal accidents involving at least one drunk driver = 16.401273885350317\n",
      "For Missouri the percentage of fatal accidents involving at least one drunk driver = 27.534562211981566\n",
      "For Montana the percentage of fatal accidents involving at least one drunk driver = 47.953216374269005\n",
      "For Nebraska the percentage of fatal accidents involving at least one drunk driver = 38.659793814432994\n",
      "For Nevada the percentage of fatal accidents involving at least one drunk driver = 29.7029702970297\n",
      "For New Hampshire the percentage of fatal accidents involving at least one drunk driver = 30.0\n",
      "For New Jersey the percentage of fatal accidents involving at least one drunk driver = 21.968365553602812\n",
      "For New Mexico the percentage of fatal accidents involving at least one drunk driver = 29.05027932960894\n",
      "For New York the percentage of fatal accidents involving at least one drunk driver = 17.2020725388601\n",
      "For North Carolina the percentage of fatal accidents involving at least one drunk driver = 28.41246290801187\n",
      "For North Dakota the percentage of fatal accidents involving at least one drunk driver = 48.03921568627451\n",
      "For Ohio the percentage of fatal accidents involving at least one drunk driver = 33.523266856600195\n",
      "For Oklahoma the percentage of fatal accidents involving at least one drunk driver = 27.564102564102566\n",
      "For Oregon the percentage of fatal accidents involving at least one drunk driver = 26.905829596412556\n",
      "For Pennsylvania the percentage of fatal accidents involving at least one drunk driver = 23.621323529411764\n",
      "For Rhode Island the percentage of fatal accidents involving at least one drunk driver = 37.5\n",
      "For South Carolina the percentage of fatal accidents involving at least one drunk driver = 35.47008547008547\n",
      "For South Dakota the percentage of fatal accidents involving at least one drunk driver = 41.74757281553398\n",
      "For Tennessee the percentage of fatal accidents involving at least one drunk driver = 22.56728778467909\n",
      "For Texas the percentage of fatal accidents involving at least one drunk driver = 24.713824479013795\n",
      "For Utah the percentage of fatal accidents involving at least one drunk driver = 19.69111969111969\n",
      "For Vermont the percentage of fatal accidents involving at least one drunk driver = 47.368421052631575\n",
      "For Virginia the percentage of fatal accidents involving at least one drunk driver = 29.224376731301938\n",
      "For Washington the percentage of fatal accidents involving at least one drunk driver = 31.547619047619047\n",
      "For West Virginia the percentage of fatal accidents involving at least one drunk driver = 27.6\n",
      "For Wisconsin the percentage of fatal accidents involving at least one drunk driver = 31.985294117647058\n",
      "For Wyoming the percentage of fatal accidents involving at least one drunk driver = 28.999999999999996\n"
     ]
    }
   ],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "US_DF = []\n",
    "myState = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['STATE'] = df['STATE'].map(lambda x:stateName[x])\n",
    "    df['DAY_WEEK'] = df['DAY_WEEK'].map(lambda x:day_to_weekDay[x])\n",
    "    US_DF.append(df)\n",
    "\n",
    "def percent(index):\n",
    "    fil = US_DF[index].loc[US_DF[index].DRUNK_DR >=1]\n",
    "    percent = (len(fil.DRUNK_DR)/len(US_DF[index].DRUNK_DR))*100\n",
    "    return percent\n",
    "for i in range(len(myState)):\n",
    "    print('For',myState[i], 'the percentage of fatal accidents involving at least one drunk driver =',percent(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then made a list to store all the data for each state. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName.\n",
    "\n",
    "* For each state in the US_df list, I want to return the unique state and the percentage of fatal accidents involved at least one drunk driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. For whole United States, what is the percentage of fatal accidents involved at least one drunk driver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = (glob.glob('FARS/accident*.csv'))\n",
    "for file in files:\n",
    "    US_df = pd.concat([pd.read_csv(file) for file in files], ignore_index = True)\n",
    "    US_df['STATE'] = US_df['STATE'].map(lambda x:stateName[x])\n",
    "data = pd.DataFrame(US_df)\n",
    "drunk_driver_fatalities = data.loc[data.DRUNK_DR >=1]\n",
    "percent = (len(drunk_driver_fatalities.DRUNK_DR)/len(data.DRUNK_DR))*100\n",
    "print(\"For the whole United States, the percentage of fatal accident involving at least one drunk driver is: {} \".format(percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used the glob function to read the csv file from the folder and then concatenated all the data for each state to represent the data for the whole United States. Each file that represents the accident data for a state was read with pandas and I made a mapping function to convert the state code to the stateName.\n",
    "\n",
    "* I made a pandas dataFrame for the whole US_df which is the concatenated data of all the states, I want to print the percentage of fatal accidents involved at least one drunk driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. For whole United States, how many fatalities were caused by each type of collision? Use the MAN_COLL column. The values in the column are below.\n",
    "\n",
    "          0\tNot Collision with Motor Vehicle in Transport\n",
    "          1\tFront-to-Rear\n",
    "          2\tFront-to-Front\n",
    "          6\tAngle\n",
    "          7\tSideswipe – Same Direction\n",
    "          8\tSideswipe – Opposite Direction\n",
    "          9\tRear-to-Side\n",
    "         10\tRear-to-Rear\n",
    "         11\tOther (End-Swipes and Others)\n",
    "         98\tNot Reported\n",
    "         99\tUnknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Collision with Motor Vehicle in Transport</th>\n",
       "      <td>21296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angle</th>\n",
       "      <td>6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front-to-Front</th>\n",
       "      <td>3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front-to-Rear</th>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sideswipe-Same Direction</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sideswipe-Opposite Direction</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rear-to-Side</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Reported</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rear-to-Rear</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Count\n",
       "Not Collision with Motor Vehicle in Transport  21296\n",
       "Angle                                           6122\n",
       "Front-to-Front                                  3511\n",
       "Front-to-Rear                                   2350\n",
       "Sideswipe-Same Direction                         519\n",
       "Sideswipe-Opposite Direction                     421\n",
       "Others                                            86\n",
       "Unknown                                           77\n",
       "Rear-to-Side                                      32\n",
       "Not Reported                                      23\n",
       "Rear-to-Rear                                       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files = (glob.glob('FARS/accident*.csv'))\n",
    "#for file in files:\n",
    "#    US_df = pd.concat([pd.read_csv(file) for file in files], ignore_index = True)\n",
    "#    US_df['STATE'] = US_df['STATE'].map(lambda x:stateName[x])\n",
    "#data = pd.DataFrame(US_df)\n",
    "\n",
    "collisionType=[\"Not Collision with Motor Vehicle in Transport\",\"Angle\",\"Front-to-Front\",\"Front-to-Rear\",\n",
    "        \"Sideswipe-Same Direction\",\"Sideswipe-Opposite Direction\",\"Others\",\"Unknown\",\"Rear-to-Side\",\"Not Reported\",\n",
    "      \"Rear-to-Rear\"]\n",
    "\n",
    "count = data['MAN_COLL'].value_counts()\n",
    "df = pd.DataFrame(count.values, collisionType, columns = ['Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used data file which i had read earlier from the folder and then concatenated all the data for each state to represent the data for the whole United States. Each file that represents the accident data for a state was read with pandas, so instead of reloading the data, I understand that the whole united states data had been saved in the data as pandas dataFrame.\n",
    "\n",
    "* I made a list of the collision type and then counted on the whole united states the MAN_COL columns and then got the counts by the collision type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. For each state, what is its fatal accident rate per 10,000 people? To calculate this, count the number of accidents in a state, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mississippi', 2.1035601415548593),\n",
       " ('Alabama', 1.9277673594216287),\n",
       " ('South Carolina', 1.8871644990485545),\n",
       " ('Kentucky', 1.7199742206747213),\n",
       " ('New Mexico', 1.7166706946090786),\n",
       " ('Wyoming', 1.7096647347455163),\n",
       " ('Montana', 1.6463583708176721),\n",
       " ('Arkansas', 1.633073212880798),\n",
       " ('Oklahoma', 1.591346746040186),\n",
       " ('Louisiana', 1.5022970847967747),\n",
       " ('Tennessee', 1.452761781356645),\n",
       " ('Missouri', 1.4250121815557457),\n",
       " ('Florida', 1.4198859259871026),\n",
       " ('Idaho', 1.380931009401045),\n",
       " ('Georgia', 1.378759349287641),\n",
       " ('West Virginia', 1.3671384752687386),\n",
       " ('North Dakota', 1.3500135001350013),\n",
       " ('North Carolina', 1.3272041705717286),\n",
       " ('Kansas', 1.3103000243144913),\n",
       " ('Arizona', 1.252055034838974),\n",
       " ('Texas', 1.2209341870244692),\n",
       " ('Delaware', 1.2175946627367749),\n",
       " ('South Dakota', 1.195530804069912),\n",
       " ('Indiana', 1.157671374178532),\n",
       " ('Iowa', 1.1370645019002712),\n",
       " ('Maine', 1.1351403364225188),\n",
       " ('Oregon', 1.0915349992376386),\n",
       " ('Alaska', 1.0518905710147508),\n",
       " ('Nevada', 1.0308738203639427),\n",
       " ('Nebraska', 1.0169830934423987),\n",
       " ('Colorado', 1.0090224326662875),\n",
       " ('Michigan', 0.9865660906160953),\n",
       " ('New Hampshire', 0.9737718302790604),\n",
       " ('Wisconsin', 0.9423312339325162),\n",
       " ('Vermont', 0.9144081853970617),\n",
       " ('Ohio', 0.9059970811923094),\n",
       " ('Virginia', 0.8580549012523798),\n",
       " ('California', 0.8542750754546031),\n",
       " ('Pennsylvania', 0.8508585029347971),\n",
       " ('Utah', 0.8507644233311796),\n",
       " ('Maryland', 0.7834347372306778),\n",
       " ('Connecticut', 0.7832348715118523),\n",
       " ('Illinois', 0.7814127537468469),\n",
       " ('Hawaii', 0.762940414353639),\n",
       " ('Washington', 0.6922188829070557),\n",
       " ('Minnesota', 0.6461479986606457),\n",
       " ('New Jersey', 0.6337420765533698),\n",
       " ('Massachusetts', 0.5261059178709094),\n",
       " ('New York', 0.4864821973226238),\n",
       " ('Rhode Island', 0.4538723824328695),\n",
       " ('District of Columbia', 0.37993032662317927)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "censusFile = pd.read_csv('FARS/nst-est2017-alldata.csv')\n",
    "StatePopDict = pd.Series(censusFile.POPESTIMATE2016.values, index=censusFile.NAME).to_dict()\n",
    "stateList = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "state_fatal_dict={}\n",
    "for i in range(len(US_DF)):\n",
    "    s = stateList[i]\n",
    "    fatal_cnt = US_DF[i]['FATALS'].value_counts().sum()\n",
    "    fatal_rate = (fatal_cnt/StatePopDict[s]) * 10000\n",
    "    state_fatal_dict[s] = fatal_rate\n",
    "\n",
    "sorted_pairs = sorted(state_fatal_dict.items(), key=itemgetter(1), reverse = True)\n",
    "sorted_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I read the census file containing the population estimate csv file from the folder and then made a list to store all the data for each state in the stateList. I made a series of the state with the population estimate for 2016.\n",
    "\n",
    "* For each state in the US_df list above, I want to get fatal accident rate and the corresponding population estimate for 2016 for the state from the nst-est2017-alldata.csv Census data file and then calculate the total fatal accidents caused by drunk driving per 10,000 people and then sort the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. For each state, what is the rate of fatal accidents caused by drunk driving per 10,000 people? To calculate this, count the number of accidents in which a drunk driver was involved, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Montana', 0.7894817918540884),\n",
       " ('South Carolina', 0.6693788607736325),\n",
       " ('North Dakota', 0.6485358971236771),\n",
       " ('South Dakota', 0.49910509296122535),\n",
       " ('New Mexico', 0.4986976319534754),\n",
       " ('Wyoming', 0.4958027730761998),\n",
       " ('Alaska', 0.47200217930149074),\n",
       " ('Louisiana', 0.44386050232631985),\n",
       " ('Oklahoma', 0.4386404492290257),\n",
       " ('Vermont', 0.4331407193986082),\n",
       " ('Kentucky', 0.4283028858823028),\n",
       " ('Nebraska', 0.39316356705247374),\n",
       " ('Idaho', 0.3928510630192628),\n",
       " ('Missouri', 0.3923708656587825),\n",
       " ('Arkansas', 0.38149661120576017),\n",
       " ('Delaware', 0.37787420567693014),\n",
       " ('West Virginia', 0.3773302191741718),\n",
       " ('North Carolina', 0.377091392677279),\n",
       " ('Maine', 0.35332182656859856),\n",
       " ('Mississippi', 0.3450106601594753),\n",
       " ('Colorado', 0.3399573787477815),\n",
       " ('Tennessee', 0.3278489320245844),\n",
       " ('Nevada', 0.30620014466255724),\n",
       " ('Ohio', 0.3037198192411066),\n",
       " ('Texas', 0.3017395319855013),\n",
       " ('Florida', 0.3015986811762581),\n",
       " ('Wisconsin', 0.3014074167357681),\n",
       " ('Georgia', 0.2996038248452047),\n",
       " ('Iowa', 0.2938481297045645),\n",
       " ('Oregon', 0.29368654688008217),\n",
       " ('Arizona', 0.29238741854043093),\n",
       " ('New Hampshire', 0.29213154908371813),\n",
       " ('Alabama', 0.2818613962014548),\n",
       " ('Kansas', 0.26825039867855727),\n",
       " ('Virginia', 0.2507611969033963),\n",
       " ('Michigan', 0.24462812246909307),\n",
       " ('Connecticut', 0.23134695493054713),\n",
       " ('Washington', 0.21837857615520206),\n",
       " ('Illinois', 0.20645501469881797),\n",
       " ('Indiana', 0.20500430584411503),\n",
       " ('Pennsylvania', 0.2009840397557379),\n",
       " ('California', 0.20027241119534483),\n",
       " ('Hawaii', 0.18898524025273625),\n",
       " ('Maryland', 0.18589976815643203),\n",
       " ('Minnesota', 0.17918389878824625),\n",
       " ('Rhode Island', 0.17020214341232606),\n",
       " ('Utah', 0.16752504088760678),\n",
       " ('Massachusetts', 0.15094403771783751),\n",
       " ('District of Columbia', 0.14612704870122278),\n",
       " ('New Jersey', 0.13922277604423763),\n",
       " ('New York', 0.08368502047207829)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "censusFile = pd.read_csv('FARS/nst-est2017-alldata.csv')\n",
    "StatePopDict = pd.Series(censusFile.POPESTIMATE2016.values, index=censusFile.NAME).to_dict()\n",
    "stateList = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "state_fatal_dict={}\n",
    "\n",
    "state_drunk_dict = {}\n",
    "for i in range(len(US_DF)):\n",
    "    s = stateList[i]\n",
    "    total_drunkDr_accident = US_DF[i]['FATALS'].value_counts().sum() - US_DF[i]['DRUNK_DR'].value_counts()[0]\n",
    "    drunk_rate = (total_drunkDr_accident/StatePopDict[s]) * 10000\n",
    "    state_drunk_dict[s] = drunk_rate\n",
    "\n",
    "sorted_pairs = sorted(state_drunk_dict.items(), key=itemgetter(1), reverse = True)\n",
    "sorted_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I read the census file containing the population estimate csv file from the folder and then made a list to store all the data for each state in the stateList. I made a series of the state with the population estimate for 2016.\n",
    "\n",
    "* For each state in the US_df list above, I want to get total fatal accidents caused by drunk driving and the corresponding population estimate for 2016 for the state from the nst-est2017-alldata.csv Census data file and then calculate the total fatal accidents caused by drunk driving per 10,000 people and then sort the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
